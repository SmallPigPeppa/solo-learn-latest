defaults:
  - _self_
  - augmentations: asymmetric.yaml
  - wandb: private.yaml
  - override hydra/hydra_logging: disabled
  - override hydra/job_logging: disabled

# disable hydra outputs
hydra:
  output_subdir: null
  run:
    dir: .

name: "byol-imagenet-cifar-r18"
method: "byol"
backbone:
  name: "resnet18"
method_kwargs:
  proj_hidden_dim: 4096
  proj_output_dim: 256
  pred_hidden_dim: 4096
momentum:
  base_tau: 0.99
  final_tau: 1.0
data:
  dataset: imagenet-cifar
  train_path: "/mnt/mmtech01/dataset/lzy/ILSVRC2012/train"
  val_path: "/mnt/mmtech01/dataset/lzy/ILSVRC2012/val"
#  train_path: "/mnt/mmtech01/dataset/lzy/imagenet-cub/train"
#  val_path: "/mnt/mmtech01/dataset/lzy/imagenet-cub/val"
  format: "dali"
  num_workers: 4
optimizer:
  name: "lars"
  batch_size: 512
  lr: 1.2
#  batch_size: 256
#  lr: 1.2
  classifier_lr: 0.2
  weight_decay: 1e-6
  kwargs:
    clip_lr: False
    eta: 0.001
    exclude_bias_n_norm: True
scheduler:
  name: "warmup_cosine"
checkpoint:
  enabled: True
  dir: "trained_models"
  frequency: 1
auto_resume:
  enabled: True

# overwrite PL stuff
max_epochs: 1000
devices: [ 0, 1,2,3,4,5,6,7 ]
sync_batchnorm: True
accelerator: "gpu"
strategy: "ddp"
precision: 16-mixed
#accumulate_grad_batches: 16
